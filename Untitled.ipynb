{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-33a4c0ed535f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TkAgg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as plt\n",
    "plt.use('TkAgg')\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def main():\n",
    "    Dataset()\n",
    "\n",
    "\n",
    "def Dataset():\n",
    "    # Importing the dataset\n",
    "    dataset = pd.read_csv('Complete.csv')\n",
    "    X = dataset.iloc[:, 0:10].values\n",
    "    y = dataset.iloc[:, 11].values\n",
    "\n",
    "    LabelEncoding(X,y)\n",
    "\n",
    "def LabelEncoding(X,y):\n",
    "    # Encoding categorical data\n",
    "\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    labelencoder_X_2 = LabelEncoder()\n",
    "    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "    onehotencoder = OneHotEncoder(categorical_features=[1])\n",
    "    X = onehotencoder.fit_transform(X).toarray()\n",
    "    X = X[:, 1:]\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Feature Scaling\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    ModelClassifier(X_train,X_test,y_train,y_test)\n",
    "\n",
    "def ModelClassifier(X_train,X_test,y_train,y_test):\n",
    "    # Initialising the classifier\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(output_dim=6, init='uniform', activation='relu', input_dim=11))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(output_dim=6, init='uniform', activation='relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "    # Compiling\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fitting the training set\n",
    "    classifier.fit(X_train, y_train, batch_size=10, nb_epoch=100)\n",
    "\n",
    "    # Getting the Score\n",
    "    score = classifier.evaluate(X_test, y_test, batch_size=10)\n",
    "    print(score)\n",
    "\n",
    "    Predction(classifier,X_test,y_test)\n",
    "\n",
    "\n",
    "def Predction(classifier,X_test,y_test):\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "if __name__ == '__main__': main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
